{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNqYy0odK4Nx2sd9z3yc7dG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/steveola/niya_ml_data/blob/main/Module_10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yRRo1RSbVEcy"
      },
      "outputs": [],
      "source": [
        "# Import our essential toolkits\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load our dataset\n",
        "df = pd.read_csv('student_data.csv')\n",
        "print(\"Data Loaded Successfully!\")\n",
        "print(df.head())\n",
        "\n",
        "# X is our Feature Matrix (everything we use to make a prediction)\n",
        "X = df[['Hours_Studied', 'Previous_Grade']]\n",
        "# y is our Label Vector (the thing we want to predict)\n",
        "y = df['Pass']\n",
        "print(\"Features (X):\")\n",
        "print(X.head())\n",
        "print(\"\\nLabels (y):\")\n",
        "print(y.head())\n",
        "\n",
        "# Split the data: 80% for training, 20% for testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "print(f\"Training set size: {X_train.shape[0]} students\")\n",
        "print(f\"Testing set size: {X_test.shape[0]} students\")\n",
        "\n",
        "# Create a Decision Tree classifier\n",
        "model = DecisionTreeClassifier(random_state=42)\n",
        "# TRAIN THE MODEL! This is the magic line.\n",
        "model.fit(X_train, y_train)\n",
        "print(\"Model training complete!\")\n",
        "\n",
        "\n",
        "# Use the trained model to make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"Predictions for the test set:\")\n",
        "print(y_pred)\n",
        "\n",
        "\n",
        "# Calculate Accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy: {accuracy:.2f} ({accuracy*100:.0f}%)\")\n",
        "# Create a Confusion Matrix to see WHERE we went wrong\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(cm)\n",
        "# Let's make a visual heatmap of the confusion matrix\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "xticklabels=['Predicted Fail', 'Predicted Pass'],\n",
        "yticklabels=['Actual Fail', 'Actual Pass'])\n",
        "plt.title('Confusion Matrix for our Student Pass/Fail Predictor')\n",
        "plt.show()\n",
        "\n",
        "# Let's try a less complex tree\n",
        "better_model = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
        "better_model.fit(X_train, y_train)\n",
        "better_pred = better_model.predict(X_test)\n",
        "print(f\"Improved Model Accuracy: {accuracy_score(y_test, better_pred):.2f}\")\n",
        "\n",
        "\n",
        "# Step 1: Import Libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "# Step 2: Load and Prepare the Data (using our preprocessed student data)\n",
        "# Let's assume X contains ['Hours_Studied', 'Previous_Grade'] and y is 'Pass' (1 or 0)\n",
        "X = df[['Hours_Studied', 'Previous_Grade']].values\n",
        "y = df['Pass'].values\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "# It's CRUCIAL to scale data for neural networks!\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Step 3: Build the Neural Network Model\n",
        "model = keras.Sequential([\n",
        "# Input Layer: 2 features, so 2 inputs. Keras figures this out automatically.\n",
        "# First Hidden Layer: 8 neurons, ReLU activation.\n",
        "keras.layers.Dense(8, activation='relu', input_shape=(2,)),\n",
        "# Second Hidden Layer: 4 neurons, ReLU activation.\n",
        "keras.layers.Dense(4, activation='relu'),\n",
        "# Output Layer: 1 neuron (for binary classification), Sigmoid activation.\n",
        "keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "# Let's look at our creation!\n",
        "print(\"Model Architecture:\")\n",
        "model.summary()\n",
        "\n",
        "# Step 4: Compile the Model (Configure the learning process)\n",
        "model.compile(optimizer='adam', # A powerful and popular optimizer\n",
        "loss='binary_crossentropy', # The loss function for binary classification\n",
        "metrics=['accuracy']) # What to monitor during training\n",
        "print(\"Model compiled and ready for training!\")\n",
        "\"The moment of truth... let's train it!\"\n",
        "\n",
        "\n",
        "# Step 5: Train the Model (The \"Fitting\" process)\n",
        "# Number of passes through the training data\n",
        "# Check performance on test set after each epoch\n",
        "history = model.fit(X_train_scaled, y_train,epochs=50,\n",
        "validation_data=(X_test_scaled, y_test), verbose=1) # Shows a progress bar\n",
        "print(\"Training complete!\")\n",
        "\n",
        "# Step 6: Evaluate the Final Model\n",
        "test_loss, test_accuracy = model.evaluate(X_test_scaled, y_test, verbose=0)\n",
        "print(f\"\\nFinal Test Accuracy: {test_accuracy:.4f}\")\n",
        "# Step 7: Make a Prediction\n",
        "new_student = np.array([[12, 80]]) # A student who studied 12 hours with an 80 previousm grade\n",
        "new_student_scaled = scaler.transform(new_student)\n",
        "prediction_prob = model.predict(new_student_scaled)\n",
        "print(f\"Probability of passing: {prediction_prob[0][0]:.4f}\")\n",
        "\n",
        "\n",
        "# First, let's re-train our best model from Module 8 to make sure we have it\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import joblib\n",
        "# Assume X_train and y_train are already defined\n",
        "final_model = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
        "final_model.fit(X_train, y_train)\n",
        "# Now, let's save it using joblib\n",
        "joblib.dump(final_model, 'my_student_predictor.joblib')\n",
        "print(\"Model saved successfully! Check your Colab files folder on the left.\")\n",
        "\n",
        "# Imagine we are in a brand new notebook or a different app.\n",
        "# We can load the model back into memory\n",
        "loaded_model = joblib.load('my_student_predictor.joblib')\n",
        "# And use it to make a prediction just like before!\n",
        "new_student = [[10, 75]] # A student who studied 10 hours with a previous grade of 75%\n",
        "prediction = loaded_model.predict(new_student)\n",
        "print(f\"This student is predicted to: {'PASS' if prediction[0] == 1 else 'FAIL'}\")\n",
        "\n",
        "\n",
        "# This is a simplified example. Running a full Flask app in Colab requires extra steps.\n",
        "from flask import Flask, request, jsonify\n",
        "import joblib\n",
        "# Load our saved model\n",
        "model = joblib.load('my_student_predictor.joblib')\n",
        "app = Flask(__name__)\n",
        "@app.route('/predict', methods=['POST'])\n",
        "def predict():\n",
        "# Get the JSON data from the request\n",
        "    data = request.get_json()\n",
        "    # Extract the features from the data\n",
        "    hours_studied = data['hours_studied']\n",
        "    previous_grade = data['previous_grade']\n",
        "    # Make a prediction\n",
        "    prediction = model.predict([[hours_studied, previous_grade]])\n",
        "    # Return the prediction as a JSON response\n",
        "    result = {'prediction': 'PASS' if prediction[0] == 1 else 'FAIL'}\n",
        "    return jsonify(result)\n",
        "\n",
        "# This would run the server if we were on a local machine\n",
        "# if __name__ == '__main__':\n",
        "# app.run(debug=True)\n",
        "\n",
        "import streamlit as st\n",
        "import joblib\n",
        "# Load the model\n",
        "model = joblib.load('my_student_predictor.joblib')\n",
        "# Create the web app\n",
        "st.title(\" Student Success Predictor\")\n",
        "st.write(\"Will a student pass their final exam?\")\n",
        "# Create input widgets\n",
        "hours = st.slider(\"Hours Studied\", 0, 20, 10)\n",
        "previous_grade = st.slider(\"Previous Grade (%)\", 0, 100, 75)\n",
        "\n",
        "# When the user clicks the button, make a prediction\n",
        "if st.button('Predict'):\n",
        "    prediction = model.predict([[hours, previous_grade]])\n",
        "    result = 'PASS' if prediction[0] == 1 else 'FAIL'\n",
        "    st.success(f\"This student is predicted to: {result}\")\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}